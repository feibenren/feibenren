---
title: CHARSET
categories: 
- COMPUTER
---
# charset(字符编码)到底是什么东西?

先来说说这几个概念

### 字符

比如汉字`你`,英语`A`,使用特定的图形表示特定的意思，这个图形就是字符，不同语言的字符不一样

### 字符集

字符集那就是一个特定的字符的集合，比如汉字字符集,表示的就是所有的汉字的集合，英语字符集，表示的就是所有英文字母的集合


但是在计算机中无法存储这些字符集，只能使用01来表示，也就是说，需要使用`数字来表示图形(字符)`

那也简单，一一编号即可

对应的编号就叫做`编码字符集`

刚开始各个国家搞各自的字符集，比如`ASCII`就是拉丁字母字符集，中国人自己搞的字符集`GBK`

这就导致一个问题，那就是会乱码，如果按照GBK的方式打开ASCII的编码，会乱码

最后得出共识，全球的字符都放到一个编码表中，就不会出现乱码

刚开始有两个团队在做这个编码表，`UNICODE`和`UCS`，后来两个合并成`UNICODE`

`UNICODE`，收录了全球几乎所有的字符,一共有2的21次方个字符，并且可能会随时增加，也就是`100万`个字符左右

UNICODE的收录方式是分类收录的，有这几个概念

- code point(码点):一个编号就是一个码点
- plane(平面):一个plane是2的16次方(65536)个,一共有2的5次方个(17)plane，所以一共有2的21的字符
- BMP:基本平面,是第一个plane，这里面收录全球最最常用的字符
- SMP:辅助平面，第二到第17个plane，里面收录的全球是非常用的字符



# 字符编码(charset)

unicode最是定义了编号，具体怎么存储？

这里涉及到`编码方案`

最简单的思路，逐个对应

## UTF-32

使用2的32次方来对应UNICODE，绰绰有余，也就是4byte对应一个`code point`

其中UTF(unicode transform format):unicode字符转换格式

简单明了

## UTF-8

但是使用utf-32有一个问题，那就是太浪费存储空间，如果只存储英文字母的话，使用ASCII来存储，1byte就表示一个字符

使用UTF-32存储的话，就会扩大4倍的空间

utf-8解决了这个问题，它使用变长存储字符


- 如果一个字节的第一位为0，那么代表当前字符为单字节字符，占用一个字节的空间。0之后的所有部分（7个bit）代表在Unicode中的序号。

- 如果一个字节以110开头，那么代表当前字符为双字节字符，占用2个字节的空间。110之后的所有部分（5个bit）加上后一个字节的除10外的部分（6个bit）代表在Unicode中的序号。且第二个字节以10开头
- 如果一个字节以1110开头，那么代表当前字符为三字节字符，占用3个字节的空间。110之后的所有部分（5个bit）加上后两个字节的除10外的部分（12个bit）代表在Unicode中的序号。且第二、第三个字节以10开头
- 如果一个字节以10开头，那么代表当前字节为多字节字符的第二个字节。10之后的所有部分（6个bit）和之前的部分一同组成在Unicode中的序号。

```
Byte 1	    Byte 2	    Byte3       Byte4
0xxx xxxx	 	 
110x xxxx	10xx xxxx	 
1110 xxxx	10xx xxxx	10xx xxxx   
1111 0xxx	10xx xxxx	10xx xxxx   10xx xxxx 
```

UTF-8规则稍微复杂一些，主要就是为了实现变长字符，最大化的节省存储空间

可见，UTF8最小使用1byte，最大使用4byte来标示一个字符


每个byte之前到底怎么分割，用`标志位`表示

> 在utf8中，汉字得用3byte存储


# UTF-16

utf-8编码固然更好，但是还是有些不完美

- 为了变长，使用了太多的标志位

- 计算规则复杂

这样就导致假如一个文件，重要是汉字的话，

还有一种思路:

因为我们最长使用的是基本平面(BMF)的字符，一共就2的16次方个，2byte就足够了

剩下的在想其他办法存储

这就是`UTF-16`的基本思路

- 使用2byte来存储BMP
- 使用4byte来存储SMP

和utf-8使用标识位不同，utf-16不使用标识位来区分byte，也就是说，1byte中的8位，都表示实际意义

那么他怎么区分字符是用2byte表示，还是使用4byte来表示？

是这样的

```
0000    0000    0000    0000
```
表示BMP的时候，这8bit都表示有意义的，但是在设计的时候，特意留了一段一个段是默认是空的

比如下面有一个空`xx`
```
0000    0000    00xx    0000
```
在表示BMP的时候，`xx`始终是`00`

但是在表示SMP的时候，`xx`就不为空

这个时候，UTF-16就使用4byte来标示一个字符

```
0000    0000    00xx    0000    aaaa    aaaa    aaaa    aaaa
```

这样`xx`和`aaaa    aaaa    aaaa    aaaa`合起来，表示SMP中的字符

设计的也很巧妙

使用UTF-16有一个有利有弊

- 对英文字母来说，所有的字符至少2byte，但是utf-8只有1byte
- 对汉字来说，基本的字符使用2byte就够了，但是在utf-8中得3byte

总的来说，似乎是UTF-16最均衡，但是对英语国家来说，这个方案很糟糕

但是对于编程语言来说，似乎这个方案是最合适的

- 放弃了一定的存储优势
- 最大化包含了所有字符

java中的char类型中就指明使用的编码方案是`UTF-16`

> 还有我发现某些文件存储的时候有的格式写的是`unicode`，但是`file xxx`查看的时候，使用的却是`utf-16`,还有，某些语言中，默认说unicode编码，默认就是utf-16格式的编码


### javascript语言中使用的字符编码方案

由于时间原因，js语言使用的是`ucs-2`不是`utf-16`

原因就是js发明的时候，还没有`utf-16`，那个时候只有`ucs-2`

后来两个团队合伙，推出UTF-16，

`ucs-2`其实实现的是utf-16的MBP，也就是2byte的那部分，4byte的没有实现

也就是说，ucs-2是utf-16的子集

其实绝大部分情况下，使用js的时候根本感觉不到两者的区别，因为SMP几乎使用不到

# 综述

UTF-32,UTF-8,UTF-16,三者都实现了unicode的所有字符的format

只是各种实现的方式不同，各种方式实现起来有利有弊


所以，charset到底是什么意思，其实就是`编码方案`



# 乱码

这个也好理解，比如字符`a`,使用utf8编码，存储起来是`001`

如果使用`GBK`编码方式来打开这个文件,可能对应的是字符`你`,

这就是乱码的原因


# 还有哪些常见的charset有哪些?

在unicode推出之前，各个国家地区搞出了自己的一套charset

- ASCII:最早的charset，只有英文字母和阿拉伯数字，英语国家使用足够
- GBK:中国汉字charset,中国标准
- GB2312


# base64


还有一种编码方式比较特殊

那就是针对二进制文件的编码，这种编码方式不应该算是一种`charset`，因为二进制文件不是`char`

思路是这样的

- 使用64个字符(a-zA-Z0-9+-=)
- 每三个字节一组(24bit)
- 分成四分，每份前面补充两个0，一共32bit
- 每一份，因为前面是两个0，所以实际有意义是的6位,也就是64
- 使用对应的字符来标示每一位即可

可以看到，由于添加了0，使得3byte变成了4byte，数据变大了三分之一左右


# 摩斯电码

摩斯电码也许是最古老的charset，思路和01很像

简单说就是通过`按住开关的时间的长短来表示01`

比如长按就是1，短按就是0

然后几个01组成一个字符，比如`0001`表示`a`

以此类推

早期的摩斯电码就只有26个英文字母和10个阿拉伯数字，很简洁

# LINKS

- [http://cenalulu.github.io/linux/character-encoding/](http://cenalulu.github.io/linux/character-encoding/)
- [http://www.ruanyifeng.com/blog/2014/12/unicode.html](http://www.ruanyifeng.com/blog/2014/12/unicode.html)
- [http://www.ruanyifeng.com/blog/2014/12/unicodejavascript.html](http://www.ruanyifeng.com/blog/2014/12/unicodejavascript.html)
- [http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)